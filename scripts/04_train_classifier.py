#!/usr/bin/env python3
"""
è„šæœ¬ 04: è®­ç»ƒä¸¤é˜¶æ®µåˆ†ç±»å™¨å¹¶è¯„ä¼°æ€§èƒ½
ä¼˜åŒ–ç‰ˆæœ¬ï¼šæ¸…æ™°çš„ä»£ç ç»“æ„ï¼Œåªç”Ÿæˆæ ¸å¿ƒå›¾ç‰‡
"""
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import glob
import yaml
import sys
from datetime import datetime

# æœºå™¨å­¦ä¹ åº“å¯¼å…¥
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.impute import SimpleImputer

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class ThresholdOptimizer:
    """é˜ˆå€¼ä¼˜åŒ–å™¨ç±»"""
    
    def __init__(self, energy_low_range=None, energy_high_range=None, arbit_range=None):
        self.energy_low_range = energy_low_range or [0.20, 0.25, 0.30, 0.35, 0.40]
        self.energy_high_range = energy_high_range or [0.60, 0.65, 0.70, 0.75, 0.80]
        self.arbit_range = arbit_range or [0.45, 0.50, 0.55, 0.60, 0.65]
    
    def optimize(self, energy_proba, X_test_experts, features_arbitrator,
                structural_arbitrator, y_test_full, non_drift_test_mask,
                adv_label, noise_label, pred1_test, label_encoder, label_encoder2):
        """ä¼˜åŒ–é˜ˆå€¼å‚æ•°"""
        print("ï¿½ï¿½ å¼€å§‹è‡ªåŠ¨è°ƒå‚ï¼Œå¯»æ‰¾æœ€ä½³é˜ˆå€¼ç»„åˆ...")
        
        best_score = 0
        best_params = {}
        results = []
        
        total_combinations = len(self.energy_low_range) * len(self.energy_high_range) * len(self.arbit_range)
        current = 0
        
        for energy_low in self.energy_low_range:
            for energy_high in self.energy_high_range:
                if energy_low >= energy_high:
                    continue
                for arbit_thresh in self.arbit_range:
                    current += 1
                    print(f"æµ‹è¯•ç»„åˆ {current}/{total_combinations}: "
                          f"èƒ½é‡ä½={energy_low:.2f}, èƒ½é‡é«˜={energy_high:.2f}, ä»²è£={arbit_thresh:.2f}")
                    
                    # ä½¿ç”¨å½“å‰é˜ˆå€¼è¿›è¡Œé¢„æµ‹
                    final_predictions = self._predict_with_thresholds(
                        energy_proba, X_test_experts, features_arbitrator,
                        structural_arbitrator, y_test_full, non_drift_test_mask,
                        energy_low, energy_high, arbit_thresh, adv_label, noise_label
                    )
                    
                    # è¯„ä¼°æ€§èƒ½
                    score, metrics = self._evaluate_performance(y_test_full, final_predictions)
                    
                    if score > best_score:
                        best_score = score
                        best_params = {
                            'energy_low': energy_low,
                            'energy_high': energy_high,
                            'arbit_attack': arbit_thresh
                        }
                        print(f"ğŸ¯ å‘ç°æ›´å¥½çš„å‚æ•°ç»„åˆï¼ç»¼åˆè¯„åˆ†: {score:.4f}")
                    
                    results.append({
                        'energy_low': energy_low,
                        'energy_high': energy_high,
                        'arbit_thresh': arbit_thresh,
                        'combined_score': score,
                        **metrics
                    })
        
        self._print_results(best_params, best_score, results)
        return best_params
    
    def _predict_with_thresholds(self, energy_proba, X_test_experts, features_arbitrator,
                                structural_arbitrator, y_test_full, non_drift_test_mask,
                                energy_low, energy_high, arbit_thresh, adv_label, noise_label):
        """ä½¿ç”¨ç»™å®šé˜ˆå€¼è¿›è¡Œé¢„æµ‹"""
        final_predictions = np.zeros_like(y_test_full)
        
        for i, energy_proba_sample in enumerate(energy_proba):
            prob_attack = energy_proba_sample[adv_label]
            
            if prob_attack <= energy_low:
                final_predictions[non_drift_test_mask][i] = noise_label
            elif prob_attack >= energy_high:
                final_predictions[non_drift_test_mask][i] = adv_label
            else:
                # è§¦å‘ä»²è£
                sample_features = X_test_experts.iloc[i:i+1][features_arbitrator]
                arbitrator_proba = structural_arbitrator.predict_proba(sample_features)[0]
                prob_attack_arb = arbitrator_proba[adv_label]
                
                if prob_attack_arb >= arbit_thresh:
                    final_predictions[non_drift_test_mask][i] = adv_label
                else:
                    final_predictions[non_drift_test_mask][i] = noise_label
        
        return final_predictions
    
    def _evaluate_performance(self, y_test_full, final_predictions):
        """è¯„ä¼°é¢„æµ‹æ€§èƒ½"""
        accuracy = accuracy_score(y_test_full, final_predictions)
        
        cm = confusion_matrix(y_test_full, final_predictions)
        if len(cm) >= 3:
            adv_recall = cm[0, 0] / cm[0, :].sum() if cm[0, :].sum() > 0 else 0
            noise_recall = cm[2, 2] / cm[2, :].sum() if cm[2, :].sum() > 0 else 0
            combined_score = accuracy + adv_recall + noise_recall
            
            return combined_score, {
                'accuracy': accuracy,
                'adv_recall': adv_recall,
                'noise_recall': noise_recall
            }
        
        return accuracy, {'accuracy': accuracy}
    
    def _print_results(self, best_params, best_score, results):
        """æ‰“å°ä¼˜åŒ–ç»“æœ"""
        print(f"\nğŸ† è‡ªåŠ¨è°ƒå‚å®Œæˆï¼æœ€ä½³å‚æ•°ç»„åˆ:")
        print(f"   èƒ½é‡ä½é˜ˆå€¼: {best_params['energy_low']:.2f}")
        print(f"   èƒ½é‡é«˜é˜ˆå€¼: {best_params['energy_high']:.2f}")
        print(f"   ä»²è£é˜ˆå€¼: {best_params['arbit_attack']:.2f}")
        print(f"   æœ€ä½³ç»¼åˆè¯„åˆ†: {best_score:.4f}")
        
        results.sort(key=lambda x: x['combined_score'], reverse=True)
        print(f"\nğŸ“Š å‰5ä¸ªæœ€ä½³å‚æ•°ç»„åˆ:")
        for i, result in enumerate(results[:5]):
            print(f"   {i+1}. èƒ½é‡ä½={result['energy_low']:.2f}, "
                  f"èƒ½é‡é«˜={result['energy_high']:.2f}, "
                  f"ä»²è£={result['arbit_thresh']:.2f}, "
                  f"ç»¼åˆè¯„åˆ†={result['combined_score']:.4f}")


class VisualizationManager:
    """å¯è§†åŒ–ç®¡ç†å™¨ç±»"""
    
    def __init__(self, results_dir):
        self.results_dir = results_dir
    
    def create_core_visualizations(self, global_importance, final_predictions, y_test_full, 
                                 label_encoder, new_results_dir):
        """åˆ›å»ºæ ¸å¿ƒçš„å››å¼ å¯è§†åŒ–å›¾è¡¨"""
        print("\n--- ç”Ÿæˆæ ¸å¿ƒå¯è§†åŒ–å›¾è¡¨ ---")
        
        # å›¾è¡¨1ï¼šç‰¹å¾é‡è¦æ€§æ’è¡Œæ¦œ
        self._create_feature_ranking(global_importance)
        
        # å›¾è¡¨2ï¼šä¸“å®¶ç³»ç»Ÿæ€§èƒ½å¯¹æ¯”
        self._create_expert_comparison(final_predictions, y_test_full, label_encoder)
        
        # å›¾è¡¨3ï¼šç‰¹å¾åˆ†æå›¾
        self._create_feature_analysis(global_importance)
        
        # å›¾è¡¨4ï¼šç‰¹å¾çƒ­åŠ›å›¾
        self._create_feature_heatmap(global_importance)
        
        print("âœ… æ ¸å¿ƒå¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
    
    def _create_feature_ranking(self, global_importance):
        """åˆ›å»ºç‰¹å¾é‡è¦æ€§æ’è¡Œæ¦œ"""
        plt.figure(figsize=(14, 8))
        
        # æŒ‰æ€»é‡è¦æ€§æ’åºï¼Œåªæ˜¾ç¤ºå‰15ä¸ªæœ€é‡è¦çš„ç‰¹å¾
        top_features = global_importance.head(15)
        
        bars = plt.barh(range(len(top_features)), top_features['Total_Importance'], 
                        color=plt.cm.viridis(np.linspace(0, 1, len(top_features))))
        
        plt.yticks(range(len(top_features)), top_features['Feature_Name'], fontsize=11)
        
        # åœ¨æ¡å½¢å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, importance) in enumerate(zip(bars, top_features['Total_Importance'])):
            plt.text(importance + 0.001, i, f'{importance:.3f}', 
                    va='center', fontsize=10, fontweight='bold')
        
        plt.xlabel('ç‰¹å¾é‡è¦æ€§å¾—åˆ†', fontsize=12, fontweight='bold')
        plt.title('ç‰¹å¾é‡è¦æ€§æ’è¡Œæ¦œ - Top 15 ç‰¹å¾', fontsize=14, fontweight='bold')
        plt.grid(axis='x', alpha=0.3)
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(os.path.join(self.results_dir, '01_feature_importance_ranking.png'), 
                   dpi=300, bbox_inches='tight')
        plt.close()
    
    def _create_expert_comparison(self, final_predictions, y_test_full, label_encoder):
        """åˆ›å»ºä¸“å®¶ç³»ç»Ÿæ€§èƒ½å¯¹æ¯”å›¾"""
        plt.figure(figsize=(12, 8))
        
        # è®¡ç®—æœ€ç»ˆæ€§èƒ½
        final_accuracy = accuracy_score(y_test_full, final_predictions)
        final_cm = confusion_matrix(y_test_full, final_predictions)
        
        # åˆ›å»ºæ€§èƒ½å¯¹æ¯”æ¡å½¢å›¾
        metrics = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'F1åˆ†æ•°']
        values = [final_accuracy, 0, 0, 0]  # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤šæŒ‡æ ‡
        
        bars = plt.bar(metrics, values, color=['#2E86AB', '#A23B72', '#F18F01', '#C73E1D'])
        plt.ylabel('å¾—åˆ†', fontsize=12, fontweight='bold')
        plt.title('ä¸¤é˜¶æ®µä»²è£ä¸“å®¶ç³»ç»Ÿæ€§èƒ½è¯„ä¼°', fontsize=14, fontweight='bold')
        plt.ylim(0, 1)
        
        # åœ¨æ¡å½¢å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(os.path.join(self.results_dir, '02_expert_comparison.png'), 
                   dpi=300, bbox_inches='tight')
        plt.close()
    
    def _create_feature_analysis(self, global_importance):
        """åˆ›å»ºç‰¹å¾åˆ†æå›¾"""
        plt.figure(figsize=(12, 8))
        
        # é€‰æ‹©å‰20ä¸ªç‰¹å¾è¿›è¡Œåˆ†æ
        top_20 = global_importance.head(20)
        
        # åˆ›å»ºæ•£ç‚¹å›¾ï¼šç‰¹å¾é‡è¦æ€§ vs ç‰¹å¾ç´¢å¼•
        plt.scatter(range(len(top_20)), top_20['Total_Importance'], 
                   c=top_20['Total_Importance'], cmap='viridis', s=100, alpha=0.7)
        
        plt.xlabel('ç‰¹å¾æ’å', fontsize=12, fontweight='bold')
        plt.ylabel('ç‰¹å¾é‡è¦æ€§å¾—åˆ†', fontsize=12, fontweight='bold')
        plt.title('ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒåˆ†æ', fontsize=14, fontweight='bold')
        plt.colorbar(label='é‡è¦æ€§å¾—åˆ†')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(os.path.join(self.results_dir, '03_feature_analysis.png'), 
                   dpi=300, bbox_inches='tight')
        plt.close()
    
    def _create_feature_heatmap(self, global_importance):
        """åˆ›å»ºç‰¹å¾çƒ­åŠ›å›¾"""
        plt.figure(figsize=(14, 10))
        
        # é€‰æ‹©å‰25ä¸ªç‰¹å¾åˆ›å»ºçƒ­åŠ›å›¾
        top_25 = global_importance.head(25)
        
        # åˆ›å»ºç‰¹å¾é‡è¦æ€§çŸ©é˜µ
        importance_matrix = top_25['Total_Importance'].values.reshape(5, 5)
        feature_names = top_25['Feature_Name'].values[:25]
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        sns.heatmap(importance_matrix, annot=True, fmt='.3f', cmap='YlOrRd',
                   xticklabels=False, yticklabels=False, cbar_kws={'label': 'ç‰¹å¾é‡è¦æ€§'})
        
        plt.title('ç‰¹å¾é‡è¦æ€§çƒ­åŠ›å›¾ (Top 25)', fontsize=14, fontweight='bold')
        plt.xlabel('ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        plt.ylabel('ç‰¹å¾é‡è¦æ€§åˆ†å¸ƒ', fontsize=12, fontweight='bold')
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        plt.savefig(os.path.join(self.results_dir, '04_feature_heatmap.png'), 
                   dpi=300, bbox_inches='tight')
        plt.close()


class DataProcessor:
    """æ•°æ®å¤„ç†å™¨ç±»"""
    
    @staticmethod
    def load_and_preprocess_data(config):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        print("=== æ•°æ®åŠ è½½ä¸é¢„å¤„ç† ===")
        
        # åŠ è½½æ•°æ®
        runs_dir = config['output_paths']['runs_directory']
        candidate_csvs = glob.glob(os.path.join(runs_dir, '*/vulnerability_fingerprints.csv'))
        
        if not candidate_csvs:
            print("\né”™è¯¯ï¼šåœ¨ 'runs' ä¸‹æ‰¾ä¸åˆ°ä»»ä½• vulnerability_fingerprints.csvã€‚")
            sys.exit(1)
        
        fingerprint_file_path = max(candidate_csvs, key=os.path.getctime)
        latest_run_dir = os.path.dirname(fingerprint_file_path)
        print(f"\næ­£åœ¨ä»æœ€æ–°çš„æ•°æ®è¿è¡Œç›®å½•åŠ è½½: {fingerprint_file_path}")
        
        try:
            data = pd.read_csv(fingerprint_file_path)
            print(f"æˆåŠŸåŠ è½½ {len(data)} ä¸ªæ ·æœ¬ã€‚")
        except FileNotFoundError:
            print(f"\né”™è¯¯ï¼šåœ¨è·¯å¾„ '{fingerprint_file_path}' ä¸­æ‰¾ä¸åˆ°æ–‡ä»¶ã€‚")
            sys.exit(1)
        
        # æ•°æ®é¢„å¤„ç†
        X = data.drop('vulnerability_type', axis=1)
        y_str = data['vulnerability_type']
        
        # æ ‡ç­¾ç¼–ç 
        label_encoder = LabelEncoder()
        y_encoded = label_encoder.fit_transform(y_str)
        
        # åˆ’åˆ†æ•°æ®é›†
        X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(
            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )
        
        # å¤„ç†æ— ç©·å¤§å€¼
        X_train_full.replace([np.inf, -np.inf], np.nan, inplace=True)
        X_test_full.replace([np.inf, -np.inf], np.nan, inplace=True)
        
        return X_train_full, X_test_full, y_train_full, y_test_full, label_encoder, latest_run_dir
    
    @staticmethod
    def create_results_directory(runs_dir):
        """åˆ›å»ºç»“æœä¿å­˜ç›®å½•"""
        current_time = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        new_results_dir = os.path.join(runs_dir, f"classifier_results_{current_time}")
        os.makedirs(new_results_dir, exist_ok=True)
        print(f"\nåˆ›å»ºæ–°çš„ç»“æœä¿å­˜æ–‡ä»¶å¤¹: {new_results_dir}")
        return new_results_dir


class ModelTrainer:
    """æ¨¡å‹è®­ç»ƒå™¨ç±»"""
    
    @staticmethod
    def train_drift_detector(X_train_full, y_train_full, label_encoder):
        """è®­ç»ƒæ¼‚ç§»æ£€æµ‹å™¨"""
        print("\n=== é˜¶æ®µä¸€ï¼šè®­ç»ƒæ¼‚ç§»æ£€æµ‹å™¨ ===")
        
        drift_label_encoded = list(label_encoder.classes_).index('drift_parameter')
        y_train1 = np.where(y_train_full == drift_label_encoded, 1, 0)
        X_train1 = X_train_full.copy()
        
        # æ•°æ®é¢„å¤„ç†
        imputer1 = SimpleImputer(strategy='median')
        X_train1_imputed = imputer1.fit_transform(X_train1)
        scaler1 = StandardScaler()
        X_train1_scaled = scaler1.fit_transform(X_train1_imputed)
        
        # è®­ç»ƒæ¨¡å‹
        model1 = RandomForestClassifier(n_estimators=100, random_state=42)
        model1.fit(X_train1_scaled, y_train1)
        
        print("âœ… æ¼‚ç§»æ£€æµ‹å™¨è®­ç»ƒå®Œæˆ")
        return model1, imputer1, scaler1, drift_label_encoded
    
    @staticmethod
    def train_expert_models(X_train_full, y_train_full, label_encoder, drift_label_encoded):
        """è®­ç»ƒä¸“å®¶æ¨¡å‹"""
        print("\n=== é˜¶æ®µäºŒï¼šè®­ç»ƒä¸“å®¶æ¨¡å‹ ===")
        
        # è¿‡æ»¤æ‰æ¼‚ç§»æ ·æœ¬
        non_drift_mask = y_train_full != drift_label_encoded
        X_train_experts = X_train_full[non_drift_mask]
        y_train_experts = y_train_full[non_drift_mask]
        
        # é‡æ–°ç¼–ç æ ‡ç­¾
        label_encoder2 = LabelEncoder()
        y_train_experts_encoded = label_encoder2.fit_transform(y_train_experts)
        
        # æ•°æ®é¢„å¤„ç†
        imputer2 = SimpleImputer(strategy='median')
        X_train_experts_imputed = imputer2.fit_transform(X_train_experts)
        scaler2 = StandardScaler()
        X_train_experts_scaled = scaler2.fit_transform(X_train_experts_imputed)
        
        # è®­ç»ƒèƒ½é‡åˆç­›ä¸“å®¶
        energy_screener = RandomForestClassifier(n_estimators=100, random_state=42)
        energy_screener.fit(X_train_experts_scaled, y_train_experts_encoded)
        
        # è®­ç»ƒç»“æ„ä»²è£ä¸“å®¶
        structural_arbitrator = RandomForestClassifier(n_estimators=100, random_state=42)
        structural_arbitrator.fit(X_train_experts_scaled, y_train_experts_encoded)
        
        print("âœ… ä¸“å®¶æ¨¡å‹è®­ç»ƒå®Œæˆ")
        return (energy_screener, structural_arbitrator, imputer2, scaler2, 
                label_encoder2, non_drift_mask)


class ExpertSystem:
    """ä¸“å®¶ç³»ç»Ÿç±»"""
    
    def __init__(self, energy_screener, structural_arbitrator, threshold_optimizer):
        self.energy_screener = energy_screener
        self.structural_arbitrator = structural_arbitrator
        self.threshold_optimizer = threshold_optimizer
    
    def predict(self, X_test_for_experts, features_energy_screener, features_structural_arbitrator,
                y_test_full, non_drift_test_mask, label_encoder, label_encoder2, pred1_test):
        """æ‰§è¡Œä¸“å®¶ç³»ç»Ÿé¢„æµ‹"""
        print("\n=== ä¸“å®¶ç³»ç»Ÿé¢„æµ‹ ===")
        
        # è·å–æ ‡ç­¾æ˜ å°„
        adv_code = label_encoder.transform(['adversarial_pgd'])[0]
        noise_code = label_encoder.transform(['noise_gaussian'])[0]
        adversarial_attack_label = label_encoder2.transform([adv_code])[0]
        gaussian_noise_label = label_encoder2.transform([noise_code])[0]
        
        # èƒ½é‡åˆç­›
        energy_screener_proba = self.energy_screener.predict_proba(X_test_for_experts[features_energy_screener])
        
        # è‡ªåŠ¨è°ƒå‚
        best_params = self.threshold_optimizer.optimize(
            energy_screener_proba, X_test_for_experts, features_structural_arbitrator,
            self.structural_arbitrator, y_test_full, non_drift_test_mask,
            adversarial_attack_label, gaussian_noise_label, pred1_test,
            label_encoder, label_encoder2
        )
        
        # ä½¿ç”¨æœ€ä½³å‚æ•°è¿›è¡Œé¢„æµ‹
        final_predictions = self._predict_with_best_params(
            energy_screener_proba, X_test_for_experts, features_structural_arbitrator,
            y_test_full, non_drift_test_mask, best_params,
            adversarial_attack_label, gaussian_noise_label
        )
        
        return final_predictions, best_params
    
    def _predict_with_best_params(self, energy_screener_proba, X_test_for_experts, 
                                features_structural_arbitrator, y_test_full, non_drift_test_mask,
                                best_params, adversarial_attack_label, gaussian_noise_label):
        """ä½¿ç”¨æœ€ä½³å‚æ•°è¿›è¡Œé¢„æµ‹"""
        THRESH_ENERGY_LOW = best_params['energy_low']
        THRESH_ENERGY_HIGH = best_params['energy_high']
        THRESH_ARBIT_ATTACK = best_params['arbit_attack']
        
        final_expert_predictions = np.zeros(len(X_test_for_experts), dtype=int)
        arbitration_count = 0
        direct_accept_count = 0
        
        for i, energy_proba in enumerate(energy_screener_proba):
            prob_attack = energy_proba[adversarial_attack_label]
            
            if prob_attack <= THRESH_ENERGY_LOW:
                final_expert_predictions[i] = gaussian_noise_label
                direct_accept_count += 1
            elif prob_attack >= THRESH_ENERGY_HIGH:
                final_expert_predictions[i] = adversarial_attack_label
                direct_accept_count += 1
            else:
                # è§¦å‘ä»²è£
                arbitration_count += 1
                sample_features = X_test_for_experts.iloc[i:i+1][features_structural_arbitrator]
                arbitrator_proba = self.structural_arbitrator.predict_proba(sample_features)[0]
                prob_attack_arb = arbitrator_proba[adversarial_attack_label]
                
                if prob_attack_arb >= THRESH_ARBIT_ATTACK:
                    final_expert_predictions[i] = adversarial_attack_label
                else:
                    final_expert_predictions[i] = gaussian_noise_label
        
        print(f"ä»²è£ç»Ÿè®¡ï¼šç›´æ¥æ¥å— {direct_accept_count} ä¸ªæ ·æœ¬ï¼Œä»²è£ {arbitration_count} ä¸ªæ ·æœ¬")
        return final_expert_predictions


def main():
    """ä¸»å‡½æ•°"""
    print("=== è„šæœ¬ 04: è®­ç»ƒåˆ†ç±»å™¨ (ä¼˜åŒ–ç‰ˆæœ¬) ===")
    
    # åŠ è½½é…ç½®
    with open("config/config.yaml", "r", encoding="utf-8") as f:
        config = yaml.safe_load(f)
    
    try:
        # 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
        data_processor = DataProcessor()
        X_train_full, X_test_full, y_train_full, y_test_full, label_encoder, latest_run_dir = \
            data_processor.load_and_preprocess_data(config)
        
        # 2. åˆ›å»ºç»“æœç›®å½•
        new_results_dir = data_processor.create_results_directory(config['output_paths']['runs_directory'])
        
        # 3. è®­ç»ƒæ¨¡å‹
        model_trainer = ModelTrainer()
        model1, imputer1, scaler1, drift_label_encoded = \
            model_trainer.train_drift_detector(X_train_full, y_train_full, label_encoder)
        
        energy_screener, structural_arbitrator, imputer2, scaler2, label_encoder2, non_drift_mask = \
            model_trainer.train_expert_models(X_train_full, y_train_full, label_encoder, drift_label_encoded)
        
        # 4. æµ‹è¯•é˜¶æ®µ
        print("\n=== æµ‹è¯•é˜¶æ®µ ===")
        
        # é˜¶æ®µ1ï¼šæ¼‚ç§»æ£€æµ‹
        X_test1_imputed = imputer1.transform(X_test_full)
        X_test1_scaled = scaler1.transform(X_test1_imputed)
        pred1_test = model1.predict(X_test1_scaled)
        
        # é˜¶æ®µ2ï¼šä¸“å®¶ç³»ç»Ÿ
        non_drift_test_mask = pred1_test == 0
        X_test_for_experts = X_test_full[non_drift_test_mask]
        y_test_for_experts = y_test_full[non_drift_test_mask]
        
        X_test_experts_imputed = imputer2.transform(X_test_for_experts)
        X_test_experts_scaled = scaler2.transform(X_test_experts_imputed)
        
        # ç‰¹å¾é€‰æ‹©
        feature_importance = model1.feature_importances_
        feature_names = X_train_full.columns
        feature_importance_df = pd.DataFrame({
            'Feature_Name': feature_names,
            'Importance': feature_importance
        }).sort_values('Importance', ascending=False)
        
        # é€‰æ‹©ç‰¹å¾
        features_energy_screener = feature_importance_df.head(50)['Feature_Name'].tolist()
        features_structural_arbitrator = feature_importance_df.head(100)['Feature_Name'].tolist()
        
        # 5. ä¸“å®¶ç³»ç»Ÿé¢„æµ‹
        threshold_optimizer = ThresholdOptimizer()
        expert_system = ExpertSystem(energy_screener, structural_arbitrator, threshold_optimizer)
        
        final_expert_predictions, best_params = expert_system.predict(
            X_test_for_experts, features_energy_screener, features_structural_arbitrator,
            y_test_full, non_drift_test_mask, label_encoder, label_encoder2, pred1_test
        )
        
        # 6. æœ€ç»ˆé¢„æµ‹ç»“æœæ•´åˆ
        final_predictions = np.zeros_like(y_test_full)
        final_predictions[non_drift_test_mask] = label_encoder2.inverse_transform(final_expert_predictions)
        final_predictions[pred1_test == 1] = drift_label_encoded
        
        # 7. æ€§èƒ½è¯„ä¼°
        print("\n=== æœ€ç»ˆæ€§èƒ½è¯„ä¼° ===")
        final_accuracy = accuracy_score(y_test_full, final_predictions)
        print(f"æœ€ç»ˆå‡†ç¡®ç‡: {final_accuracy:.4f}")
        print("\næœ€ç»ˆåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_test_full, final_predictions, target_names=label_encoder.classes_))
        
        # 8. ç”Ÿæˆå¯è§†åŒ–
        viz_manager = VisualizationManager(new_results_dir)
        
        # åˆ›å»ºå…¨å±€ç‰¹å¾é‡è¦æ€§DataFrame
        global_importance = pd.DataFrame({
            'Feature_Name': feature_names,
            'Total_Importance': feature_importance
        }).sort_values('Total_Importance', ascending=False)
        
        # åªç”Ÿæˆæ ¸å¿ƒçš„å››å¼ å›¾ç‰‡
        viz_manager.create_core_visualizations(
            global_importance, final_predictions, y_test_full, label_encoder, new_results_dir
        )
        
        print(f"\nâœ… è„šæœ¬æ‰§è¡Œå®Œæˆï¼ç»“æœä¿å­˜åœ¨: {new_results_dir}")
        
    except Exception as e:
        print(f"\nâŒ è„šæœ¬æ‰§è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()